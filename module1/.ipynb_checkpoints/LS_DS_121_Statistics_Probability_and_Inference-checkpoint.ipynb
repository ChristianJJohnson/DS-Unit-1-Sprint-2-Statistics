{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eJGtmni-DezY"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "\n",
    "<br></br>\n",
    "<br></br>\n",
    "\n",
    "## *Data Science Unit 1 Sprint 2 Lesson 1*\n",
    "\n",
    "# Statistics, Probability and Inference\n",
    "\n",
    "## Learning Objectives\n",
    "* [Part 1](#p1): Normal Distribution Revisted\n",
    "* [Part 2](#p2): Student's T Test\n",
    "* [Part 3](#p3): Hypothesis Test & Doing it Live"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WOXkk77hbeP5"
   },
   "source": [
    "## What is Descriptive Statistics?\n",
    "\n",
    "<https://statistics.laerd.com/statistical-guides/descriptive-inferential-statistics.php>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "aGsGGy4Mb9IG",
    "outputId": "30adadef-0e5a-4efe-bd22-745b288b4804"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'a': [1,2,3,4,5], 'b': [2,4,6,8,10]})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K-73WFB5cI1_"
   },
   "outputs": [],
   "source": [
    "# How can we quickly look at some descriptive statistics of the above dataframe?\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wtobOQescQU6"
   },
   "source": [
    "## What is Inferential Statistics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![stats](https://slideplayer.com/slide/5130463/16/images/2/Statistical+Inference.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zsb1KMUSc2xe"
   },
   "source": [
    "## Hypothesis Testing (T-Tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cOnNrJembf5c"
   },
   "source": [
    "\n",
    "\n",
    "Ever thought about how long it takes to make a pancake? Have you ever compared the tooking time of a pancake on each eye of your stove? Is the cooking time different between the different eyes? Now, we can run an experiment and collect a sample of 1,000 pancakes on one eye and another 800 pancakes on the other eye. Assumed we used the same pan, batter, and technique on both eyes. Our average cooking times were 180 (5 std) and 178.5 (4.25 std) seconds repsectively. Now, we can tell those numbers are not identicial, but how confident are we that those numbers are practically the same? How do we know the slight difference isn't caused by some external randomness?\n",
    "\n",
    "Yes, today's lesson will help you figure out how long to cook your pancakes (*theoretically*). Experimentation is up to you; otherwise, you have to accept my data as true. How are going to accomplish this? With probability, statistics, inference and maple syrup (optional). \n",
    "\n",
    "<img src=\"https://images.unsplash.com/photo-1541288097308-7b8e3f58c4c6?ixlib=rb-1.2.1&ixid=eyJhcHBfaWQiOjEyMDd9&auto=format&fit=crop&w=3300&q=80\" width=400>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MOkBDGsWbMRc"
   },
   "source": [
    "## Normal Distribution Revisited\n",
    "\n",
    "What is the Normal distribution: A probability distribution of a continuous real valued random-variable. The Normal distribution properties make it useful for the *Central Limit Theorm*, because if we assume a variable follows the normal distribution, we can make certain conclusions based on probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BYlq8EYKbMRd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "mu = 0 # mean\n",
    "sigma = 1 # standard deviation\n",
    "sample = np.random.normal(mu, sigma, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GbVV3_TsbMRn",
    "outputId": "7ac56d23-c90c-4016-8bb1-b6dbdd0eb313"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import style\n",
    "\n",
    "style.use('fivethirtyeight')\n",
    "\n",
    "ax = sns.distplot(sample, color='r')\n",
    "ax.axvline(np.percentile(sample,97.5),0)\n",
    "ax.axvline(np.percentile(sample,2.5),0);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D3ZwR9tDc-KX"
   },
   "source": [
    "![The Normal Distribution](https://upload.wikimedia.org/wikipedia/commons/thumb/a/a9/Empirical_Rule.PNG/350px-Empirical_Rule.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we talk about the **population parameters**: we use $\\mu$ and $\\sigma$ for mean and standard deviation\n",
    "\n",
    "When we talk about the sample **sample statistics**: we use $\\bar{x}$ and s\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our first 2-sample t-test (pancake example)\n",
    "1) Null Hypothesis: (boring hypothesis)\n",
    "\n",
    "ùë•¬Ø1==ùë•¬Ø2 \n",
    "\n",
    "Or that the average cooking time between the two burners is the same.\n",
    "\n",
    "2) Alternative Hypothesis: (the opposite of the null)\n",
    "\n",
    "ùë•¬Ø1‚â†ùë•¬Ø2 \n",
    "\n",
    "ùë•¬Ø1‚àíùë•¬Ø2‚â†0 \n",
    "3) Confidence Level: The probability of seing a true result in spite of random variability. (How often do I want to make sure that I'm right.) Typically: 95%, 99%, 99.9%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 1\n",
    "mu1 = 180 # sample mean\n",
    "sigma1 = 5 # standard deviation\n",
    "sample1 = np.random.normal(mu1, sigma1, 1000)\n",
    "sample1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample 2\n",
    "mu2 = 178.5 # sample mean\n",
    "sigma2 = 4.25 # standard deviation\n",
    "sample2 = np.random.normal(mu2, sigma2, 800)\n",
    "sample2[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare\n",
    "results=ttest_ind(sample1, sample2)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the p-value?\n",
    "print(results[1])\n",
    "print('{:f}'.format(results[1]))\n",
    "print('{:.15f}'.format(results[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) T Statistic: A value that falls along a t-distribution.\n",
    "\n",
    "A vertical bar that falls on our t-distribution\n",
    "5) P-value: The p-value that we're interested in is (1-Confidence Level) or in our case: .05\n",
    "\n",
    "The probability of getting this test result (t-statistic) due to random chance.\n",
    "\n",
    "The probability of our null hypothesis being true.\n",
    "\n",
    "6) Conclusions:\n",
    "\n",
    "Due to observing a t-statistic of 8.9 and a resulting p-value of .00000000000000000109, we reject the null hypothesis that the cooking times of these two burners is the same, and suggest the alternative hypothesis, that they are different.\n",
    "\n",
    "(Because our p-value was less than .05, we reject the null hypothesis)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5BvYLMjadAnu"
   },
   "source": [
    "# Why do we use the t-distribution in hypothesis tests?\n",
    "\n",
    "![t-distribution-low-dof](https://lambdachops.com/img/t-distribution-low-dof.png)\n",
    "\n",
    "![t-distribution-approximates-normal](https://github.com/ryanallredblog/ryanallredblog.github.io/blob/master/img/t-distribution-approximates-normal.png?raw=true)\n",
    "\n",
    "### Helpful video on why we use the t-distribution\n",
    "\n",
    "<https://www.youtube.com/watch?v=Uv6nGIgZMVw>\n",
    "\n",
    "However, in order to understand it you'll need to understand what a z-score is:\n",
    "\n",
    "A z-score calculates the number of standard deviations an observations lies from the population mean. The problem is that in real-world situations, we don't know what the sample mean is, so we have to turn to using the sample mean to estimate the population mean. Because the sample mean is generated from a sample and used to estimate the population mean with some level of uncertainty, it also has its own distribution a nd spread. This means that for low sample sizes both our estimates of the sample mean and sample population are not very precise, they're kind of spread out. It's this spread that makes the t-distribution wider than the normal distribution for low sample sizes. However, with the larger the sample size, the closer the t-distribution approximates the normal distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FMhDKOFND0qY"
   },
   "source": [
    "## Student's T Test\n",
    "\n",
    ">Assuming data come from a Normal distribution, the t test provides a way to test whether the sample mean (that is the mean calculated from the data) is a good estimate of the population mean. \n",
    "\n",
    "The derivation of the t-distribution was first published in 1908 by William Gosset while working for the Guinness Brewery in Dublin. Due to proprietary issues, he had to publish under a pseudonym, and so he used the name Student.\n",
    "\n",
    "The t-distribution is essentially a distribution of means of normaly distributed data. When we use a t-statistic, we are  checking that a mean fails within a certain $\\alpha$ probability of the mean of means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fQ9rkLJmEbsk"
   },
   "outputs": [],
   "source": [
    "t_df10 = np.random.standard_t(df=10, size=10)\n",
    "t_df100 = np.random.standard_t(df=100, size=100)\n",
    "t_df1000 = np.random.standard_t(df=1000, size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "RyNKPt_tJk86",
    "outputId": "db64f558-1945-4fef-f7d7-3184212d8237"
   },
   "outputs": [],
   "source": [
    "sns.kdeplot(t_df10, color='r');\n",
    "sns.kdeplot(t_df100, color='y');\n",
    "sns.kdeplot(t_df1000, color='b');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "seQv5unnJvpM",
    "outputId": "b2f84397-b204-4864-84a1-2b29eb926bbf"
   },
   "outputs": [],
   "source": [
    "i = 10\n",
    "for sample in [t_df10, t_df100, t_df1000]:\n",
    "    print(f\"t - distribution with {i} degrees of freedom\")\n",
    "    print(\"---\" * 10)\n",
    "    print(f\"Mean: {sample.mean()}\")\n",
    "    print(f\"Standard Deviation: {sample.std()}\")\n",
    "    print(f\"Variance: {sample.var()}\")\n",
    "    i = i*10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FOvEGMysLaE2"
   },
   "source": [
    "Why is it different from normal? To better reflect the tendencies of small data and situations with unknown population standard deviation. In other words, the normal distribution is still the nice pure ideal (thanks to the central limit theorem), but the t-distribution is much more useful in many real-world situations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1yx_QilAEC6o"
   },
   "source": [
    "## Live Lecture - let's perform and interpret a t-test\n",
    "\n",
    "We'll generate our own data, so we can know and alter the \"ground truth\" that the t-test should find. We will learn about p-values and how to interpret \"statistical significance\" based on the output of a hypothesis test. We will also dig a bit deeper into how the test statistic is calculated based on the sample error, and visually what it looks like to have 1 or 2 \"tailed\" t-tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BuysRPs-Ed0v"
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from scipy.stats import ttest_ind, ttest_ind_from_stats, ttest_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data\n",
    "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/voting-records/house-votes-84.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make into a dataframe\n",
    "column_headers = ['party','handicapped-infants','water-project',\n",
    "                          'budget','physician-fee-freeze', 'el-salvador-aid',\n",
    "                          'religious-groups','anti-satellite-ban',\n",
    "                          'aid-to-contras','mx-missile','immigration',\n",
    "                          'synfuels', 'education', 'right-to-sue','crime','duty-free',\n",
    "                          'south-africa']\n",
    "\n",
    "df = pd.read_csv('house-votes-84.data', \n",
    "                 header=None, \n",
    "                 names=column_headers,\n",
    "                 na_values=\"?\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recode votes as numeric\n",
    "df = df.replace({'y': 1, 'n': 0})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many from each party?\n",
    "df['party'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how did Republicans vote?\n",
    "rep = df[df['party']=='republican']\n",
    "rep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how did Democrats vote?\n",
    "dem = df[df['party']=='democrat']\n",
    "dem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the percentage of republicans who voted \"yes\" (1) \n",
    "# on the handicapped-infants bill\n",
    "\n",
    "rep['handicapped-infants'].sum()/len(rep)\n",
    "\n",
    "# len() is counting NaN values too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NaN values from this column\n",
    "\n",
    "col = rep['handicapped-infants']\n",
    "\n",
    "np.isnan(col)\n",
    "\n",
    "handicapped_infants_no_nans = col[~np.isnan(col)]\n",
    "\n",
    "# The same column as before, but I've dropped the NaN values\n",
    "handicapped_infants_no_nans\n",
    "\n",
    "handicapped_infants_no_nans.sum()/len(handicapped_infants_no_nans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average rate of voting 'yes' on the handicapped-infants\n",
    "rep['handicapped-infants'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### water project bill (two-sample t-test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Null Hypothesis: There is no difference between average voting rates (levels of support) for the water-project bill between democrats and republicans in the house of representatives. (support is equal)\n",
    "\n",
    "ùë•¬Ø1==ùë•¬Ø2 \n",
    "Where  ùë•¬Ø1  is the mean of republican votes and  ùë•¬Ø2  is the mean of democrat votes.\n",
    "\n",
    "2) Alternative Hypothesis:\n",
    "\n",
    "ùë•¬Ø1‚â†ùë•¬Ø2 \n",
    "Levels of support between the two parties will differ.\n",
    "\n",
    "3) 95% Confidence Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the mean support of Republicans?\n",
    "rep['water-project'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the mean support of Democrats?\n",
    "dem['water-project'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare with a t-test:\n",
    "ttest_ind(rep['water-project'], dem['water-project'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# account for NaN's\n",
    "ttest_ind(rep['water-project'], dem['water-project'], nan_policy='omit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You could also remove NaN values from this column\n",
    "\n",
    "col = rep['water-project']\n",
    "rep_water_project_no_nans = col[~np.isnan(col)]\n",
    "\n",
    "col = dem['water-project']\n",
    "dem_water_project_no_nans = col[~np.isnan(col)]\n",
    "\n",
    "# My sample sizes for the two samples:\n",
    "print(len(rep_water_project_no_nans))\n",
    "print(len(dem_water_project_no_nans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I have multiple samples (using a 2-sample t-test) I will use the smaller of the two samples to determine my degrees of freedom\n",
    "\n",
    "So in this case, df = 148-1 = 147"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) T-statistic: .089\n",
    "\n",
    "5) P-value: .929\n",
    "\n",
    "I want to reject the null hypothesis if my p-value is < .05 or if my p-value is less than (1-confidence_level)\n",
    "\n",
    "Conclusion: due to a p-value of .929 I fail to reject the null hypothesis that republican and democrat support for the water-project bill is different.\n",
    "\n",
    "I never say that I \"accept\" the null hypothesis, I just say that I \"fail to reject\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-sample T-test example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm only using one sample, and my null hypothesis will be different.\n",
    "\n",
    "We're looking at Democrat support of the South-Africa bill\n",
    "\n",
    "1a) Null Hypothesis:\n",
    "\n",
    "ùë•¬Ø1  (average dem support for SA bill) == 1.\n",
    "\n",
    "This says that 100% of democrats support this bill. Full support.\n",
    "\n",
    "1b) Null Hypothesis:\n",
    "\n",
    "ùë•¬Ø1  (average dem support for SA bill) == .5\n",
    "\n",
    "This says that 50% of democrats support this bill. The party is split.\n",
    "\n",
    "1c) Null Hypothesis:\n",
    "\n",
    "ùë•¬Ø1  (average dem support for SA bill) == 0.\n",
    "\n",
    "This says that 0% of democrats support this bill. The party is against the bill.\n",
    "\n",
    "1d) Null Hypothesis:\n",
    "\n",
    "ùë•¬Ø1  (average dem support for SA bill) == .78245\n",
    "\n",
    "This says that 0% of democrats support this bill. The party is against the bill.\n",
    "\n",
    "**With 1-sample t-tests I can frame that I'm asking through my choice of null hypothesis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Null Hypothesis:  ùë•¬Ø1  (average dem support for SA bill) == .5\n",
    "\n",
    "This says that 50% of democrats support this bill. The party is split.\n",
    "\n",
    "2) Alternative Hypothesis: Support is not equal to .5 or 50%\n",
    "\n",
    "ùë•¬Ø1  (average dem support for SA bill)  ‚â†  .5\n",
    "\n",
    "This says nothing about if support is greater than or less than 50%, it's just saying that it's not 50% - it's different, it's something other than 50%.\n",
    "\n",
    "3) Confidence Level: 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from scipy.stats import ttest_1samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conduct the t-test\n",
    "ttest_1samp(dem['south-africa'], .5, nan_policy='omit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to a p-value of (basically 0) we reject the null hypothesis that democrat support for the South Africa bill is .5 (split party) and conclude that it is something different.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what is the average support among Democrats?\n",
    "dem['south-africa'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is it significantly different from 90%?\n",
    "ttest_1samp(dem['south-africa'], .9, nan_policy='omit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fail to reject the null hypothesis:\n",
    "\n",
    "I conclude that that democrat support for the South Africa bill is not significantly different from 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what about 89.9?\n",
    "ttest_1samp(dem['south-africa'], .899, nan_policy='omit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to a p-value of .048, I reject the null hypothesis that democrat support for this bill is 89.9% and suggest the alternative that it is different from 89.9%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wiq83guLcuAE"
   },
   "source": [
    "# Resources\n",
    "\n",
    "- https://homepage.divms.uiowa.edu/~mbognar/applets/t.html\n",
    "- https://rpsychologist.com/d3/tdist/\n",
    "- https://gallery.shinyapps.io/tdist/\n",
    "- https://en.wikipedia.org/wiki/Standard_deviation#Sample_standard_deviation_of_metabolic_rate_of_northern_fulmars\n",
    "- https://www.khanacademy.org/math/ap-statistics/two-sample-inference/two-sample-t-test-means/v/two-sample-t-test-for-difference-of-means"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_121_Statistics_Probability_and_Inference.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
